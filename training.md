# Documentaci√≥n del Entrenamiento del Modelo de Emociones

## üìñ Descripci√≥n General

Este documento detalla el proceso de entrenamiento del modelo de reconocimiento de emociones faciales utilizando redes neuronales convolucionales (CNN) con el dataset FER2013.

## üéØ Objetivo

Entrenar un modelo de deep learning capaz de clasificar expresiones faciales en 7 categor√≠as emocionales diferentes con alta precisi√≥n y robustez.

## üìä Dataset

### FER2013 (Facial Expression Recognition 2013)
- **Origen:** Kaggle Competition
- **Tama√±o:** ~35,000 im√°genes
- **Resoluci√≥n:** 48x48 p√≠xeles
- **Formato:** Escala de grises
- **Clases:** 7 emociones

### Distribuci√≥n de Clases
| Emoci√≥n | Cantidad Aproximada | Porcentaje |
|---------|-------------------|------------|
| Happiness | ~8,989 | 25.7% |
| Neutral | ~6,198 | 17.7% |
| Sadness | ~6,077 | 17.4% |
| Anger | ~4,953 | 14.2% |
| Surprise | ~4,002 | 11.4% |
| Fear | ~5,121 | 14.6% |
| Disgust | ~547 | 1.6% |

## üèóÔ∏è Arquitectura del Modelo

### Dise√±o de la Red Neuronal

```python
# Arquitectura CNN
input_face = Input(shape=(48, 48, 1))

# Bloque Convolucional 1
x = Conv2D(32, (3, 3), activation='relu')(input_face)
x = MaxPooling2D((2, 2))(x)

# Bloque Convolucional 2
x = Conv2D(64, (3, 3), activation='relu')(x)
x = MaxPooling2D((2, 2))(x)

# Bloque Convolucional 3
x = Conv2D(128, (3, 3), activation='relu')(x)
x = MaxPooling2D((2, 2))(x)

# Regularizaci√≥n
x = Dropout(0.25)(x)
x = Flatten()(x)

# Capas Densas
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(64, activation='relu')(x)

# Capa de Salida
output = Dense(7, activation='softmax')(x)
```

### Par√°metros del Modelo
- **Par√°metros totales:** ~2.3M
- **Par√°metros entrenables:** ~2.3M
- **Memoria requerida:** ~120MB

## ‚öôÔ∏è Configuraci√≥n de Entrenamiento

### Hiperpar√°metros
```python
# Compilaci√≥n del modelo
optimizer = 'adam'
loss = 'categorical_crossentropy'
metrics = ['accuracy']
learning_rate = 0.001  # (por defecto de Adam)

# Entrenamiento
epochs = 50
batch_size = 64
validation_split = 0.2
```

### Callbacks Implementados

#### 1. Early Stopping
```python
EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)
```
- **Prop√≥sito:** Evitar sobreentrenamiento
- **Monitoreo:** P√©rdida de validaci√≥n
- **Paciencia:** 10 √©pocas sin mejora

#### 2. Reduce Learning Rate on Plateau
```python
ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-6
)
```
- **Prop√≥sito:** Optimizaci√≥n adaptativa
- **Reducci√≥n:** 50% cuando se estanca
- **LR m√≠nimo:** 1e-6

## üìà Proceso de Entrenamiento

### 1. Preprocesamiento de Datos

```python
def preprocess_image(image):
    # Redimensionar a 48x48
    image = cv2.resize(image, (48, 48))
    
    # Normalizar valores de p√≠xeles [0, 1]
    image = image / 255.0
    
    # A√±adir dimensi√≥n de canal
    image = np.expand_dims(image, axis=-1)
    
    return image
```

### 2. Aumento de Datos (Data Augmentation)
Aunque no implementado en la versi√≥n actual, se recomienda:
- Rotaci√≥n: ¬±15¬∞
- Zoom: ¬±10%
- Desplazamiento horizontal: ¬±10%
- Volteo horizontal: Falso (las emociones son asim√©tricas)

### 3. Divisi√≥n de Datos
- **Entrenamiento:** 80% (28,000 im√°genes aprox.)
- **Validaci√≥n:** 20% (7,000 im√°genes aprox.)
- **Prueba:** Validaci√≥n cruzada en conjunto de validaci√≥n

## üìä M√©tricas de Evaluaci√≥n

### M√©tricas Principales
1. **Accuracy (Precisi√≥n Global)**
   - F√≥rmula: (TP + TN) / (TP + TN + FP + FN)
   - Objetivo: >85%

2. **Loss (P√©rdida Categ√≥rica)**
   - Funci√≥n: Categorical Crossentropy
   - Objetivo: <0.5

3. **Precision por Clase**
   - Importante para clases desbalanceadas (especialmente 'disgust')

4. **Recall por Clase**
   - Cr√≠tico para aplicaciones m√©dicas/psicol√≥gicas

### Matriz de Confusi√≥n
Se genera autom√°ticamente para analizar:
- Confusiones entre emociones similares
- Rendimiento por clase individual
- Identificaci√≥n de sesgos del modelo

## üéØ Resultados Esperados

### Rendimiento Objetivo
- **Precisi√≥n de Entrenamiento:** 90-95%
- **Precisi√≥n de Validaci√≥n:** 85-90%
- **Tiempo de Entrenamiento:** 2-4 horas (CPU) / 30-60 min (GPU)

### Curvas de Aprendizaje
El script genera autom√°ticamente:
- Gr√°fico de precisi√≥n vs. √©pocas
- Gr√°fico de p√©rdida vs. √©pocas
- Comparaci√≥n entrenamiento vs. validaci√≥n

## üîß Optimizaciones Implementadas

### 1. Dropout Regularization
- **Capa 1:** 25% despu√©s de convoluciones
- **Capa 2:** 50% en capas densas
- **Prop√≥sito:** Reducir overfitting

### 2. Batch Normalization (Recomendado)
```python
# Para futuras mejoras
x = BatchNormalization()(x)
```

### 3. Transfer Learning (Opcional)
- Usar modelos preentrenados como base
- VGG16, ResNet50 adaptados para emociones

## üöÄ Ejecuci√≥n del Entrenamiento

### Comando de Ejecuci√≥n
```bash
python modelo_emociones.py
```

### Requisitos de Hardware
- **RAM m√≠nima:** 8GB
- **Espacio en disco:** 5GB
- **GPU (opcional):** GTX 1060 o superior
- **Tiempo estimado:** 2-4 horas

### Archivos Generados
- `modelo_facial.h5` - Modelo entrenado
- `training_results_facial.png` - Gr√°ficos de entrenamiento
- Logs de entrenamiento en consola

## üìã Checklist de Entrenamiento

- [ ] Dataset descargado y organizado
- [ ] Dependencias instaladas
- [ ] Estructura de carpetas correcta
- [ ] Suficiente espacio en disco
- [ ] Ejecutar script de entrenamiento
- [ ] Validar m√©tricas obtenidas
- [ ] Guardar modelo final
- [ ] Documentar resultados

## üîç Troubleshooting

### Problemas Comunes

#### 1. Memory Error
```bash
# Reducir batch_size
batch_size = 32  # en lugar de 64
```

#### 2. Slow Training
```bash
# Verificar uso de GPU
import tensorflow as tf
print(tf.config.list_physical_devices('GPU'))
```

#### 3. Poor Convergence
- Ajustar learning rate
- Modificar arquitectura
- Aumentar datos de entrenamiento

### Logs de Debug
```python
# Activar logging detallado
import logging
logging.basicConfig(level=logging.INFO)
```

## üìö Referencias

1. [FER2013 Paper](https://arxiv.org/abs/1307.0414)
2. [CNN for Emotion Recognition](https://arxiv.org/abs/1710.07557)
3. [TensorFlow Documentation](https://www.tensorflow.org/)
4. [Keras Functional API](https://keras.io/guides/functional_api/)

## üìû Soporte

Para problemas con el entrenamiento:
1. Revisar logs de error
2. Verificar versiones de librer√≠as
3. Consultar documentaci√≥n de TensorFlow
4. Contactar al equipo de desarrollo

---

**√öltima actualizaci√≥n:** Junio 2025
**Versi√≥n del modelo:** 1.0
**Autor:** [Tu Nombre]